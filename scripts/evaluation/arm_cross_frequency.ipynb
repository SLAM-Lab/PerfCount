{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93e518bb-30f5-41ce-afb6-2ef8e8d90ad2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_size: 200\n",
      "Training R²: 0.962514093734556\n",
      "Testing R²: 0.9273944847453178\n",
      "Training Mape: 0.03663181367838967\n",
      "Testing Mape: 0.046379941513784724\n",
      "chunk_size: 400\n",
      "Training R²: 0.9085141016792825\n",
      "Testing R²: 0.8919152394366763\n",
      "Training Mape: 0.06379446466799706\n",
      "Testing Mape: 0.06812435637480878\n",
      "chunk_size: 600\n",
      "Training R²: 0.8797188580738222\n",
      "Testing R²: 0.8641202449635991\n",
      "Training Mape: 0.07538392344792026\n",
      "Testing Mape: 0.08060478841316536\n",
      "chunk_size: 800\n",
      "Training R²: 0.852132301577824\n",
      "Testing R²: 0.8178364648358242\n",
      "Training Mape: 0.08835324587340439\n",
      "Testing Mape: 0.0938292460228262\n",
      "chunk_size: 1000\n",
      "Training R²: 0.8156324176913358\n",
      "Testing R²: 0.8011282033346909\n",
      "Training Mape: 0.1011468133995732\n",
      "Testing Mape: 0.10562026335632826\n"
     ]
    }
   ],
   "source": [
    "# Arm Server 1.5GHz -> 3.0GHz\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "def process_csv_feautures(file_paths, chunk_size):\n",
    "    all_features = []\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path + '_' + str(chunk_size))\n",
    "        df = df.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        features = []\n",
    "        for index, row in df.iterrows():\n",
    "            inst = row['instructions']\n",
    "            cyc = row['cpu-cycles']\n",
    "            ipc = inst/cyc\n",
    "            features.append([\n",
    "                row['instructions'],\n",
    "                row['cpu-cycles'], \n",
    "                row['br_pred'], \n",
    "                row['br_mis_pred'], \n",
    "                row['l1d_cache'], \n",
    "                row['l1d_tlb'], \n",
    "                row['l1d_tlb_rd'], \n",
    "                row['l1d_tlb_wr'], \n",
    "                row['l2d_cache_rd'], \n",
    "                row['l2d_cache_wr'], \n",
    "                row['l2d_cache'], \n",
    "                row['l1i_cache'], \n",
    "                row['l1i_cache_refill'], \n",
    "                row['remote_access'], \n",
    "                row['dtlb_walk'], \n",
    "                row['itlb_walk'], \n",
    "                row['l1i_tlb'], \n",
    "                row['l2d_tlb'], \n",
    "                row['l2d_tlb_rd'], \n",
    "                row['l2d_tlb_wr'], \n",
    "                row['vfp_spec'], \n",
    "                row['inst_spec'], \n",
    "                row['ase_spec'], \n",
    "                row['stall_backend'], \n",
    "                row['stall_frontend'], \n",
    "                row['ll_cache_miss_rd'], \n",
    "                row['mem_access'], \n",
    "                row['mem_access_rd'], \n",
    "                row['mem_access_wr'],\n",
    "                ipc])\n",
    "        all_features.extend(features)\n",
    "    return all_features\n",
    "\n",
    "\n",
    "def process_csv_ipc(file_paths, chunk_size):\n",
    "    all_ipc_values = []\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path + '_' + str(chunk_size))\n",
    "        df = df.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        for _, row in df.iterrows():\n",
    "            all_ipc_values.append(row['instructions'] / row['cpu-cycles'])  \n",
    "    return all_ipc_values\n",
    "\n",
    "one_ghz_files = [\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_500',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_502',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_505',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_520',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_523',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_525',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_531',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_541',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_548',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_557',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_503',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_507',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_508',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_510',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_511',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_519',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_521',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_527',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_538',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_544',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_549',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_554',\n",
    "]\n",
    "    \n",
    "three_ghz_files = [\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_500',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_502',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_505',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_520',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_523',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_525',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_531',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_541',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_548',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_557',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_503',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_507',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_508',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_510',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_511',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_519',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_521',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_527',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_538',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_544',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_549',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_554',\n",
    "]\n",
    "\n",
    "chunks = [200, 400, 600, 800, 1000]\n",
    "for chunk_size in chunks:\n",
    "    in_order_hardware_counters_features = process_csv_feautures(one_ghz_files, chunk_size)\n",
    "    out_of_order_ipc = process_csv_ipc(three_ghz_files, chunk_size)\n",
    "    print('chunk_size: ' + str(chunk_size))\n",
    "    \n",
    "    data = {\n",
    "        'In Order': in_order_hardware_counters_features,\n",
    "        'Out of Order': out_of_order_ipc\n",
    "    }\n",
    "    \n",
    "    length = min(len(in_order_hardware_counters_features), len(out_of_order_ipc))\n",
    "    \n",
    "    # Shorten the longen array\n",
    "    in_order_hardware_counters_features = in_order_hardware_counters_features[:length]\n",
    "    out_of_order_ipc = out_of_order_ipc[:length]\n",
    "    \n",
    "    # separate features and target\n",
    "    X = pd.DataFrame(\n",
    "        in_order_hardware_counters_features, \n",
    "        columns=[\n",
    "            'instructions',\n",
    "            'cpu-cycles', \n",
    "            'br_pred', \n",
    "            'br_mis_pred', \n",
    "            'l1d_cache', \n",
    "            'l1d_tlb', \n",
    "            'l1d_tlb_rd', \n",
    "            'l1d_tlb_wr', \n",
    "            'l2d_cache_rd', \n",
    "            'l2d_cache_wr', \n",
    "            'l2d_cache', \n",
    "            'l1i_cache', \n",
    "            'l1i_cache_refill', \n",
    "            'remote_access', \n",
    "            'dtlb_walk', \n",
    "            'itlb_walk', \n",
    "            'l1i_tlb', \n",
    "            'l2d_tlb', \n",
    "            'l2d_tlb_rd', \n",
    "            'l2d_tlb_wr', \n",
    "            'vfp_spec', \n",
    "            'inst_spec', \n",
    "            'ase_spec', \n",
    "            'stall_backend', \n",
    "            'stall_frontend', \n",
    "            'll_cache_miss_rd', \n",
    "            'mem_access', \n",
    "            'mem_access_rd', \n",
    "            'mem_access_wr',\n",
    "            'ipc'])  # Features\n",
    "    y = pd.Series(out_of_order_ipc) \n",
    "    \n",
    "    # split \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    rf_model = RandomForestRegressor(n_estimators=100)\n",
    "    gb_model = GradientBoostingRegressor(n_estimators=100)\n",
    "    ensemble_model = gb_model\n",
    "    #ensemble_model = VotingRegressor([('rf', rf_model), ('gb', gb_model)])\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "    \n",
    "    ensemble_predictions = ensemble_model.predict(X_test)\n",
    "    # Calculate R²\n",
    "    ensemble_r2 = r2_score(y_test, ensemble_predictions)\n",
    "    \n",
    "    #bruh wut\n",
    "    train_predictions = ensemble_model.predict(X_train)\n",
    "    test_predictions = ensemble_model.predict(X_test)\n",
    "    \n",
    "    # Calculate R² for training and testing sets\n",
    "    train_r2 = r2_score(y_train, train_predictions)\n",
    "    train_mape = mean_absolute_percentage_error(y_train, train_predictions)\n",
    "    test_r2 = r2_score(y_test, test_predictions)\n",
    "    test_mape = mean_absolute_percentage_error(y_test, test_predictions)\n",
    "    \n",
    "    \n",
    "    print(f\"Training R²: {train_r2}\")\n",
    "    print(f\"Testing R²: {test_r2}\")\n",
    "    print(f\"Training Mape: {train_mape}\")\n",
    "    print(f\"Testing Mape: {test_mape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c606f18-9515-4a2f-9682-81de479d3bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_size: 200\n",
      "Training R²: 0.9699466423784385\n",
      "Testing R²: 0.9365535829119302\n",
      "Training Mape: 0.02859814798043138\n",
      "Testing Mape: 0.03448359195257257\n",
      "chunk_size: 400\n",
      "Training R²: 0.9075465555223031\n",
      "Testing R²: 0.8918238430737127\n",
      "Training Mape: 0.052290656870758616\n",
      "Testing Mape: 0.05365396097442132\n",
      "chunk_size: 600\n",
      "Training R²: 0.8740086952423789\n",
      "Testing R²: 0.8611824221160348\n",
      "Training Mape: 0.06430349062641494\n",
      "Testing Mape: 0.06775173206664781\n",
      "chunk_size: 800\n",
      "Training R²: 0.8469897823549588\n",
      "Testing R²: 0.817385162589646\n",
      "Training Mape: 0.07484558271977175\n",
      "Testing Mape: 0.08002823103012698\n",
      "chunk_size: 1000\n",
      "Training R²: 0.8256313848578662\n",
      "Testing R²: 0.8008085015224902\n",
      "Training Mape: 0.08081608321015996\n",
      "Testing Mape: 0.08566646747880259\n"
     ]
    }
   ],
   "source": [
    "# Arm Server 3.0GHz -> 1.5GHz\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "def process_csv_feautures(file_paths, chunk_size):\n",
    "    all_features = []\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path + '_' + str(chunk_size))\n",
    "        df = df.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        features = []\n",
    "        for index, row in df.iterrows():\n",
    "            inst = row['instructions']\n",
    "            cyc = row['cpu-cycles']\n",
    "            ipc = inst/cyc\n",
    "            features.append([\n",
    "                row['instructions'],\n",
    "                row['cpu-cycles'], \n",
    "                row['br_pred'], \n",
    "                row['br_mis_pred'], \n",
    "                row['l1d_cache'], \n",
    "                row['l1d_tlb'], \n",
    "                row['l1d_tlb_rd'], \n",
    "                row['l1d_tlb_wr'], \n",
    "                row['l2d_cache_rd'], \n",
    "                row['l2d_cache_wr'], \n",
    "                row['l2d_cache'], \n",
    "                row['l1i_cache'], \n",
    "                row['l1i_cache_refill'], \n",
    "                row['remote_access'], \n",
    "                row['dtlb_walk'], \n",
    "                row['itlb_walk'], \n",
    "                row['l1i_tlb'], \n",
    "                row['l2d_tlb'], \n",
    "                row['l2d_tlb_rd'], \n",
    "                row['l2d_tlb_wr'], \n",
    "                row['vfp_spec'], \n",
    "                row['inst_spec'], \n",
    "                row['ase_spec'], \n",
    "                row['stall_backend'], \n",
    "                row['stall_frontend'], \n",
    "                row['ll_cache_miss_rd'], \n",
    "                row['mem_access'], \n",
    "                row['mem_access_rd'], \n",
    "                row['mem_access_wr'],\n",
    "                ipc])\n",
    "        all_features.extend(features)\n",
    "    return all_features\n",
    "\n",
    "\n",
    "def process_csv_ipc(file_paths, chunk_size):\n",
    "    all_ipc_values = []\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path + '_' + str(chunk_size))\n",
    "        df = df.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        for _, row in df.iterrows():\n",
    "            all_ipc_values.append(row['instructions'] / row['cpu-cycles'])  \n",
    "    return all_ipc_values\n",
    "\n",
    "one_ghz_files = [\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_500',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_502',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_505',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_520',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_523',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_525',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_531',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_541',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_548',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_557',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_503',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_507',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_508',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_510',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_511',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_519',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_521',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_527',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_538',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_544',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_549',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_1.5GHz_554',\n",
    "]\n",
    "    \n",
    "three_ghz_files = [\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_500',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_502',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_505',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_520',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_523',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_525',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_531',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_541',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_548',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_557',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_503',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_507',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_508',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_510',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_511',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_519',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_521',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_527',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_538',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_544',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_549',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_server/arm_server_3.0GHz_554',\n",
    "]\n",
    "\n",
    "chunks = [200, 400, 600, 800, 1000]\n",
    "for chunk_size in chunks:\n",
    "    in_order_hardware_counters_features = process_csv_feautures(three_ghz_files, chunk_size)\n",
    "    out_of_order_ipc = process_csv_ipc(one_ghz_files, chunk_size)\n",
    "    print('chunk_size: ' + str(chunk_size))\n",
    "    \n",
    "    data = {\n",
    "        'In Order': in_order_hardware_counters_features,\n",
    "        'Out of Order': out_of_order_ipc\n",
    "    }\n",
    "    \n",
    "    length = min(len(in_order_hardware_counters_features), len(out_of_order_ipc))\n",
    "    \n",
    "    # Shorten the longen array\n",
    "    in_order_hardware_counters_features = in_order_hardware_counters_features[:length]\n",
    "    out_of_order_ipc = out_of_order_ipc[:length]\n",
    "    \n",
    "    # separate features and target\n",
    "    X = pd.DataFrame(\n",
    "        in_order_hardware_counters_features, \n",
    "        columns=[\n",
    "            'instructions',\n",
    "            'cpu-cycles', \n",
    "            'br_pred', \n",
    "            'br_mis_pred', \n",
    "            'l1d_cache', \n",
    "            'l1d_tlb', \n",
    "            'l1d_tlb_rd', \n",
    "            'l1d_tlb_wr', \n",
    "            'l2d_cache_rd', \n",
    "            'l2d_cache_wr', \n",
    "            'l2d_cache', \n",
    "            'l1i_cache', \n",
    "            'l1i_cache_refill', \n",
    "            'remote_access', \n",
    "            'dtlb_walk', \n",
    "            'itlb_walk', \n",
    "            'l1i_tlb', \n",
    "            'l2d_tlb', \n",
    "            'l2d_tlb_rd', \n",
    "            'l2d_tlb_wr', \n",
    "            'vfp_spec', \n",
    "            'inst_spec', \n",
    "            'ase_spec', \n",
    "            'stall_backend', \n",
    "            'stall_frontend', \n",
    "            'll_cache_miss_rd', \n",
    "            'mem_access', \n",
    "            'mem_access_rd', \n",
    "            'mem_access_wr',\n",
    "            'ipc'])  # Features\n",
    "    y = pd.Series(out_of_order_ipc) \n",
    "    \n",
    "    # split \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    rf_model = RandomForestRegressor(n_estimators=100)\n",
    "    gb_model = GradientBoostingRegressor(n_estimators=100)\n",
    "    ensemble_model = gb_model\n",
    "    #ensemble_model = VotingRegressor([('rf', rf_model), ('gb', gb_model)])\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "    \n",
    "    ensemble_predictions = ensemble_model.predict(X_test)\n",
    "    # Calculate R²\n",
    "    ensemble_r2 = r2_score(y_test, ensemble_predictions)\n",
    "    \n",
    "    #bruh wut\n",
    "    train_predictions = ensemble_model.predict(X_train)\n",
    "    test_predictions = ensemble_model.predict(X_test)\n",
    "    \n",
    "    # Calculate R² for training and testing sets\n",
    "    train_r2 = r2_score(y_train, train_predictions)\n",
    "    train_mape = mean_absolute_percentage_error(y_train, train_predictions)\n",
    "    test_r2 = r2_score(y_test, test_predictions)\n",
    "    test_mape = mean_absolute_percentage_error(y_test, test_predictions)\n",
    "    \n",
    "    \n",
    "    print(f\"Training R²: {train_r2}\")\n",
    "    print(f\"Testing R²: {test_r2}\")\n",
    "    print(f\"Training Mape: {train_mape}\")\n",
    "    print(f\"Testing Mape: {test_mape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c5b2d94-ab24-47ec-aa04-03748625d704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_size: 200\n",
      "Training R²: 0.9960924887983323\n",
      "Testing R²: 0.9867098454606912\n",
      "Training Mape: 0.013005811159067819\n",
      "Testing Mape: 0.016804197908178588\n",
      "chunk_size: 400\n",
      "Training R²: 0.9534646806611721\n",
      "Testing R²: 0.9275065661490149\n",
      "Training Mape: 0.04633019365089559\n",
      "Testing Mape: 0.05359849849108733\n",
      "chunk_size: 600\n",
      "Training R²: 0.9298679944682697\n",
      "Testing R²: 0.9197027566609974\n",
      "Training Mape: 0.0603648353879389\n",
      "Testing Mape: 0.06311066087952856\n",
      "chunk_size: 800\n",
      "Training R²: 0.9147767382003645\n",
      "Testing R²: 0.9030490728388032\n",
      "Training Mape: 0.06959875715684975\n",
      "Testing Mape: 0.07248515864218903\n",
      "chunk_size: 1000\n",
      "Training R²: 0.9017210560210266\n",
      "Testing R²: 0.8846832203199144\n",
      "Training Mape: 0.07514883974022456\n",
      "Testing Mape: 0.08074416792402192\n"
     ]
    }
   ],
   "source": [
    "# Arm Desktop 1.5GHz -> 3.0GHz\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "def process_csv_feautures(file_paths, chunk_size):\n",
    "    all_features = []\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path + '_' + str(chunk_size))\n",
    "        df = df.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        features = []\n",
    "        for index, row in df.iterrows():\n",
    "            inst = row['instructions']\n",
    "            cyc = row['cpu-cycles']\n",
    "            ipc = inst/cyc\n",
    "            features.append([\n",
    "            row['instructions'],\n",
    "            row['cpu-cycles'],\n",
    "            row['br_pred'],\n",
    "            row['br_mis_pred'],\n",
    "            row['l1d_cache_rd'],\n",
    "            row['l1d_cache_wr'],\n",
    "            row['l1d_cache'],\n",
    "            row['l1i_cache'],\n",
    "            row['l1i_cache_refill'],\n",
    "            row['context-switches'],\n",
    "            row['l2d_cache_rd'],\n",
    "            row['l2d_cache_wr'],\n",
    "            row['l2d_cache'],\n",
    "            row['l1d_tlb'],\n",
    "            row['l1d_tlb_refill_rd'],\n",
    "            row['l1d_tlb_refill_wr'],\n",
    "            row['dtlb_walk'],\n",
    "            row['itlb_walk'],\n",
    "            row['page-faults'],\n",
    "            row['l2d_tlb_access'],\n",
    "            row['l2i_tlb_access'],\n",
    "            row['l1i_tlb_refill'],\n",
    "            row['iTLB-loads'],\n",
    "            row['iTLB-load-misses'],\n",
    "            row['branch-loads'],\n",
    "            row['dTLB-loads'],\n",
    "            row['dTLB-load-misses'],\n",
    "            row['branch-load-misses'],\n",
    "            row['vfp_spec'],\n",
    "            row['inst_spec'],\n",
    "            row['ase_spec'],\n",
    "            row['bx_stall'],\n",
    "            row['decode_stall'],\n",
    "            row['dispatch_stall'],\n",
    "            row['fx_stall'],\n",
    "            row['ixa_stall'],\n",
    "            row['ixb_stall'],\n",
    "            row['lx_stall'],\n",
    "            row['sx_stall'],\n",
    "            row['bus_access'],\n",
    "            row['mem_access'],\n",
    "            row['mem_access_rd'],\n",
    "            row['mem_access_wr'],\n",
    "                ipc])\n",
    "        all_features.extend(features)\n",
    "    return all_features\n",
    "\n",
    "\n",
    "def process_csv_ipc(file_paths, chunk_size):\n",
    "    all_ipc_values = []\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path + '_' + str(chunk_size))\n",
    "        df = df.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        for _, row in df.iterrows():\n",
    "            all_ipc_values.append(row['instructions'] / row['cpu-cycles'])  \n",
    "    return all_ipc_values\n",
    "\n",
    "one_ghz_files = [\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_500',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_502',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_505',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_520',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_523',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_525',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_531',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_541',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_548',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_557',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_503',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_507',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_508',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_510',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_511',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_519',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_521',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_527',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_538',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_544',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_549',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_554',\n",
    "]\n",
    "    \n",
    "three_ghz_files = [\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_500',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_502',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_505',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_520',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_523',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_525',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_531',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_541',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_548',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_557',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_503',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_507',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_508',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_510',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_511',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_519',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_521',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_527',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_538',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_544',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_549',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_554',\n",
    "]\n",
    "\n",
    "chunks = [200, 400, 600, 800, 1000]\n",
    "for chunk_size in chunks:\n",
    "    in_order_hardware_counters_features = process_csv_feautures(three_ghz_files, chunk_size)\n",
    "    out_of_order_ipc = process_csv_ipc(one_ghz_files, chunk_size)\n",
    "    print('chunk_size: ' + str(chunk_size))\n",
    "    \n",
    "    data = {\n",
    "        'In Order': in_order_hardware_counters_features,\n",
    "        'Out of Order': out_of_order_ipc\n",
    "    }\n",
    "    \n",
    "    length = min(len(in_order_hardware_counters_features), len(out_of_order_ipc))\n",
    "    \n",
    "    # Shorten the longen array\n",
    "    in_order_hardware_counters_features = in_order_hardware_counters_features[:length]\n",
    "    out_of_order_ipc = out_of_order_ipc[:length]\n",
    "    \n",
    "    # separate features and target\n",
    "    X = pd.DataFrame(\n",
    "        in_order_hardware_counters_features, \n",
    "        columns=[\n",
    "            'instructions',\n",
    "            'cpu-cycles',\n",
    "            'br_pred',\n",
    "            'br_mis_pred',\n",
    "            'l1d_cache_rd',\n",
    "            'l1d_cache_wr',\n",
    "            'l1d_cache',\n",
    "            'l1i_cache',\n",
    "            'l1i_cache_refill',\n",
    "            'context-switches',\n",
    "            'l2d_cache_rd',\n",
    "            'l2d_cache_wr',\n",
    "            'l2d_cache',\n",
    "            'l1d_tlb',\n",
    "            'l1d_tlb_refill_rd',\n",
    "            'l1d_tlb_refill_wr',\n",
    "            'dtlb_walk',\n",
    "            'itlb_walk',\n",
    "            'page-faults',\n",
    "            'l2d_tlb_access',\n",
    "            'l2i_tlb_access',\n",
    "            'l1i_tlb_refill',\n",
    "            'iTLB-loads',\n",
    "            'iTLB-load-misses',\n",
    "            'branch-loads',\n",
    "            'dTLB-loads',\n",
    "            'dTLB-load-misses',\n",
    "            'branch-load-misses',\n",
    "            'vfp_spec',\n",
    "            'inst_spec',\n",
    "            'ase_spec',\n",
    "            'bx_stall',\n",
    "            'decode_stall',\n",
    "            'dispatch_stall',\n",
    "            'fx_stall',\n",
    "            'ixa_stall',\n",
    "            'ixb_stall',\n",
    "            'lx_stall',\n",
    "            'sx_stall',\n",
    "            'bus_access',\n",
    "            'mem_access',\n",
    "            'mem_access_rd',\n",
    "            'mem_access_wr',\n",
    "            'ipc'])  # Features\n",
    "    y = pd.Series(out_of_order_ipc) \n",
    "    \n",
    "    # split \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    rf_model = RandomForestRegressor(n_estimators=100)\n",
    "    gb_model = GradientBoostingRegressor(n_estimators=100)\n",
    "    ensemble_model = gb_model\n",
    "    #ensemble_model = VotingRegressor([('rf', rf_model), ('gb', gb_model)])\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "    \n",
    "    ensemble_predictions = ensemble_model.predict(X_test)\n",
    "    # Calculate R²\n",
    "    ensemble_r2 = r2_score(y_test, ensemble_predictions)\n",
    "    \n",
    "    #bruh wut\n",
    "    train_predictions = ensemble_model.predict(X_train)\n",
    "    test_predictions = ensemble_model.predict(X_test)\n",
    "    \n",
    "    # Calculate R² for training and testing sets\n",
    "    train_r2 = r2_score(y_train, train_predictions)\n",
    "    train_mape = mean_absolute_percentage_error(y_train, train_predictions)\n",
    "    test_r2 = r2_score(y_test, test_predictions)\n",
    "    test_mape = mean_absolute_percentage_error(y_test, test_predictions)\n",
    "    \n",
    "    \n",
    "    print(f\"Training R²: {train_r2}\")\n",
    "    print(f\"Testing R²: {test_r2}\")\n",
    "    print(f\"Training Mape: {train_mape}\")\n",
    "    print(f\"Testing Mape: {test_mape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1d81b56-819d-4cfb-9303-11355bb7cb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_size: 200\n",
      "Training R²: 0.9966170444492537\n",
      "Testing R²: 0.9919374892689318\n",
      "Training Mape: 0.014992654914693794\n",
      "Testing Mape: 0.01813887955373633\n",
      "chunk_size: 400\n",
      "Training R²: 0.944596996297393\n",
      "Testing R²: 0.9286214902398184\n",
      "Training Mape: 0.06191763843636014\n",
      "Testing Mape: 0.07321861514443934\n",
      "chunk_size: 600\n",
      "Training R²: 0.9282118450767473\n",
      "Testing R²: 0.8983550058183953\n",
      "Training Mape: 0.07557727515938588\n",
      "Testing Mape: 0.08173630606992813\n",
      "chunk_size: 800\n",
      "Training R²: 0.9149756618013641\n",
      "Testing R²: 0.8875079729561813\n",
      "Training Mape: 0.08493632068341207\n",
      "Testing Mape: 0.08800597824815184\n",
      "chunk_size: 1000\n",
      "Training R²: 0.897499492007171\n",
      "Testing R²: 0.8835554314594752\n",
      "Training Mape: 0.09313730170764312\n",
      "Testing Mape: 0.09485547301943073\n"
     ]
    }
   ],
   "source": [
    "# Arm Desktop 1.5GHz -> 3.0GHz\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "def process_csv_feautures(file_paths, chunk_size):\n",
    "    all_features = []\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path + '_' + str(chunk_size))\n",
    "        df = df.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        features = []\n",
    "        for index, row in df.iterrows():\n",
    "            inst = row['instructions']\n",
    "            cyc = row['cpu-cycles']\n",
    "            ipc = inst/cyc\n",
    "            features.append([\n",
    "            row['instructions'],\n",
    "            row['cpu-cycles'],\n",
    "            row['br_pred'],\n",
    "            row['br_mis_pred'],\n",
    "            row['l1d_cache_rd'],\n",
    "            row['l1d_cache_wr'],\n",
    "            row['l1d_cache'],\n",
    "            row['l1i_cache'],\n",
    "            row['l1i_cache_refill'],\n",
    "            row['context-switches'],\n",
    "            row['l2d_cache_rd'],\n",
    "            row['l2d_cache_wr'],\n",
    "            row['l2d_cache'],\n",
    "            row['l1d_tlb'],\n",
    "            row['l1d_tlb_refill_rd'],\n",
    "            row['l1d_tlb_refill_wr'],\n",
    "            row['dtlb_walk'],\n",
    "            row['itlb_walk'],\n",
    "            row['page-faults'],\n",
    "            row['l2d_tlb_access'],\n",
    "            row['l2i_tlb_access'],\n",
    "            row['l1i_tlb_refill'],\n",
    "            row['iTLB-loads'],\n",
    "            row['iTLB-load-misses'],\n",
    "            row['branch-loads'],\n",
    "            row['dTLB-loads'],\n",
    "            row['dTLB-load-misses'],\n",
    "            row['branch-load-misses'],\n",
    "            row['vfp_spec'],\n",
    "            row['inst_spec'],\n",
    "            row['ase_spec'],\n",
    "            row['bx_stall'],\n",
    "            row['decode_stall'],\n",
    "            row['dispatch_stall'],\n",
    "            row['fx_stall'],\n",
    "            row['ixa_stall'],\n",
    "            row['ixb_stall'],\n",
    "            row['lx_stall'],\n",
    "            row['sx_stall'],\n",
    "            row['bus_access'],\n",
    "            row['mem_access'],\n",
    "            row['mem_access_rd'],\n",
    "            row['mem_access_wr'],\n",
    "                ipc])\n",
    "        all_features.extend(features)\n",
    "    return all_features\n",
    "\n",
    "\n",
    "def process_csv_ipc(file_paths, chunk_size):\n",
    "    all_ipc_values = []\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path + '_' + str(chunk_size))\n",
    "        df = df.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        for _, row in df.iterrows():\n",
    "            all_ipc_values.append(row['instructions'] / row['cpu-cycles'])  \n",
    "    return all_ipc_values\n",
    "\n",
    "one_ghz_files = [\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_500',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_502',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_505',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_520',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_523',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_525',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_531',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_541',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_548',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_557',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_503',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_507',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_508',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_510',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_511',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_519',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_521',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_527',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_538',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_544',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_549',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_1.5GHz_554',\n",
    "]\n",
    "    \n",
    "three_ghz_files = [\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_500',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_502',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_505',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_520',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_523',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_525',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_531',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_541',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_548',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_557',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_503',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_507',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_508',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_510',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_511',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_519',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_521',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_527',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_538',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_544',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_549',\n",
    "    '../../Data/traces/inst_aligned_traces/arm_desktop/arm_desktop_3.0GHz_554',\n",
    "]\n",
    "\n",
    "chunks = [200, 400, 600, 800, 1000]\n",
    "for chunk_size in chunks:\n",
    "    in_order_hardware_counters_features = process_csv_feautures(one_ghz_files, chunk_size)\n",
    "    out_of_order_ipc = process_csv_ipc(three_ghz_files, chunk_size)\n",
    "    print('chunk_size: ' + str(chunk_size))\n",
    "    \n",
    "    data = {\n",
    "        'In Order': in_order_hardware_counters_features,\n",
    "        'Out of Order': out_of_order_ipc\n",
    "    }\n",
    "    \n",
    "    length = min(len(in_order_hardware_counters_features), len(out_of_order_ipc))\n",
    "    \n",
    "    # Shorten the longen array\n",
    "    in_order_hardware_counters_features = in_order_hardware_counters_features[:length]\n",
    "    out_of_order_ipc = out_of_order_ipc[:length]\n",
    "    \n",
    "    # separate features and target\n",
    "    X = pd.DataFrame(\n",
    "        in_order_hardware_counters_features, \n",
    "        columns=[\n",
    "            'instructions',\n",
    "            'cpu-cycles',\n",
    "            'br_pred',\n",
    "            'br_mis_pred',\n",
    "            'l1d_cache_rd',\n",
    "            'l1d_cache_wr',\n",
    "            'l1d_cache',\n",
    "            'l1i_cache',\n",
    "            'l1i_cache_refill',\n",
    "            'context-switches',\n",
    "            'l2d_cache_rd',\n",
    "            'l2d_cache_wr',\n",
    "            'l2d_cache',\n",
    "            'l1d_tlb',\n",
    "            'l1d_tlb_refill_rd',\n",
    "            'l1d_tlb_refill_wr',\n",
    "            'dtlb_walk',\n",
    "            'itlb_walk',\n",
    "            'page-faults',\n",
    "            'l2d_tlb_access',\n",
    "            'l2i_tlb_access',\n",
    "            'l1i_tlb_refill',\n",
    "            'iTLB-loads',\n",
    "            'iTLB-load-misses',\n",
    "            'branch-loads',\n",
    "            'dTLB-loads',\n",
    "            'dTLB-load-misses',\n",
    "            'branch-load-misses',\n",
    "            'vfp_spec',\n",
    "            'inst_spec',\n",
    "            'ase_spec',\n",
    "            'bx_stall',\n",
    "            'decode_stall',\n",
    "            'dispatch_stall',\n",
    "            'fx_stall',\n",
    "            'ixa_stall',\n",
    "            'ixb_stall',\n",
    "            'lx_stall',\n",
    "            'sx_stall',\n",
    "            'bus_access',\n",
    "            'mem_access',\n",
    "            'mem_access_rd',\n",
    "            'mem_access_wr',\n",
    "            'ipc'])  # Features\n",
    "    y = pd.Series(out_of_order_ipc) \n",
    "    \n",
    "    # split \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    rf_model = RandomForestRegressor(n_estimators=100)\n",
    "    gb_model = GradientBoostingRegressor(n_estimators=100)\n",
    "    ensemble_model = gb_model\n",
    "    #ensemble_model = VotingRegressor([('rf', rf_model), ('gb', gb_model)])\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "    \n",
    "    ensemble_predictions = ensemble_model.predict(X_test)\n",
    "    # Calculate R²\n",
    "    ensemble_r2 = r2_score(y_test, ensemble_predictions)\n",
    "    \n",
    "    #bruh wut\n",
    "    train_predictions = ensemble_model.predict(X_train)\n",
    "    test_predictions = ensemble_model.predict(X_test)\n",
    "    \n",
    "    # Calculate R² for training and testing sets\n",
    "    train_r2 = r2_score(y_train, train_predictions)\n",
    "    train_mape = mean_absolute_percentage_error(y_train, train_predictions)\n",
    "    test_r2 = r2_score(y_test, test_predictions)\n",
    "    test_mape = mean_absolute_percentage_error(y_test, test_predictions)\n",
    "    \n",
    "    \n",
    "    print(f\"Training R²: {train_r2}\")\n",
    "    print(f\"Testing R²: {test_r2}\")\n",
    "    print(f\"Training Mape: {train_mape}\")\n",
    "    print(f\"Testing Mape: {test_mape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f469f5-6b2c-4abc-9e4e-b11967a1b731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
