{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd87ff86-58fb-44c7-9251-f8b3f3723418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_lists = [\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_500', \n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_502',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_505',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_520',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_523',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_525',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_531',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_541',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_548',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_557',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_503',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_507',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_508',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_510',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_511',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_519',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_521',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_527',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_538',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_544',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_549',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_1.5GHz_554'\n",
    "]\n",
    "\n",
    "num_counters = 4\n",
    "\n",
    "for job_list in job_lists:\n",
    "    input_file = open(job_list, 'r')\n",
    "    csv_files = input_file.readlines()\n",
    "\n",
    "    merged_df = pd.read_csv('blank.csv')\n",
    "    initial_read = 0\n",
    "    \n",
    "    for csv in csv_files:\n",
    "        csv = csv.strip()\n",
    "        df1 = pd.read_csv(csv)\n",
    "        df1['time'] = df1['time'].astype(float).round(2)\n",
    "        df1.drop(df1.columns[4:], axis=1, inplace=True)\n",
    "        df1.drop(df1.columns[2], axis=1, inplace=True)\n",
    "\n",
    "        # Get counter 1\n",
    "        df2 = df1.iloc[num_counters-0::4, :]\n",
    "        counter_name = df2.iloc[num_counters-0][2]\n",
    "        df2 = df2.rename(columns={'value': counter_name})\n",
    "        df2.drop(df2.columns[2], axis=1, inplace = True)\n",
    "        df2 = df2.round({'time':2})\n",
    "       \n",
    "        # Get Counter 2\n",
    "        df3 = df1.iloc[num_counters-3::4, :]\n",
    "        counter_name = df3.iloc[num_counters-0][2]\n",
    "        df3 = df3.rename(columns={'value': counter_name})\n",
    "        df3.drop(df3.columns[2], axis=1, inplace = True)\n",
    "        df3 = df3.round({'time':2})\n",
    "        \n",
    "        # Get Counter 3\n",
    "        df4 = df1.iloc[num_counters-2::4, :]\n",
    "        counter_name = df4.iloc[num_counters-0][2]\n",
    "        df4 = df4.rename(columns={'value': counter_name})\n",
    "        df4.drop(df4.columns[2], axis=1, inplace = True)\n",
    "        df4 = df4.round({'time':2})\n",
    "        \n",
    "        # Get Counter 4\n",
    "        df5 = df1.iloc[num_counters-1::4, :]\n",
    "        counter_name = df5.iloc[num_counters-0][2]\n",
    "        df5 = df5.rename(columns={'value': counter_name})\n",
    "        df5.drop(df5.columns[2], axis=1, inplace = True)\n",
    "        df5 = df5.round({'time':2})\n",
    "\n",
    "        # Merge DFs\n",
    "        df6 = pd.merge(df2, df3, on = 'time', how='inner')\n",
    "        df6 = df6.round({'time':2})\n",
    "        df7 = pd.merge(df4, df5, on='time', how='inner')\n",
    "        df7 = df7.round({'time':2})\n",
    "        df8 = pd.merge(df6, df7, on='time', how='inner')\n",
    "        df8 = df8.round({'time':2})\n",
    "\n",
    "        if initial_read == 0:\n",
    "            merged_df = pd.merge(merged_df, df8, on='time', how = 'inner')\n",
    "            initial_read = 1\n",
    "        else:\n",
    "            df8 = df8.drop(columns=['cpu_atom/instructions/u'])\n",
    "            merged_df = pd.merge(merged_df, df8, on='time',how='inner')\n",
    "            \n",
    "    merged_df.to_csv('traces/aligned_traces/' + job_list[10:], sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09edba8c-69f0-4307-a34a-129e0f4be269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_lists = [\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_500', \n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_502',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_505',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_520',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_523',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_525',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_531',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_541',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_548',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_557',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_503',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_507',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_508',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_510',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_511',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_519',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_521',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_527',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_538',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_544',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_549',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_1.5GHz_554'\n",
    "]\n",
    "\n",
    "num_counters = 4\n",
    "\n",
    "for job_list in job_lists:\n",
    "    input_file = open(job_list, 'r')\n",
    "    csv_files = input_file.readlines()\n",
    "\n",
    "    merged_df = pd.read_csv('blank.csv')\n",
    "    initial_read = 0\n",
    "    \n",
    "    for csv in csv_files:\n",
    "        csv = csv.strip()\n",
    "        df1 = pd.read_csv(csv)\n",
    "        df1['time'] = df1['time'].astype(float).round(2)\n",
    "        df1.drop(df1.columns[4:], axis=1, inplace=True)\n",
    "        df1.drop(df1.columns[2], axis=1, inplace=True)\n",
    "\n",
    "        # Get counter 1\n",
    "        df2 = df1.iloc[num_counters-0::4, :]\n",
    "        counter_name = df2.iloc[num_counters-0][2]\n",
    "        df2 = df2.rename(columns={'value': counter_name})\n",
    "        df2.drop(df2.columns[2], axis=1, inplace = True)\n",
    "        df2 = df2.round({'time':2})\n",
    "       \n",
    "        # Get Counter 2\n",
    "        df3 = df1.iloc[num_counters-3::4, :]\n",
    "        counter_name = df3.iloc[num_counters-0][2]\n",
    "        df3 = df3.rename(columns={'value': counter_name})\n",
    "        df3.drop(df3.columns[2], axis=1, inplace = True)\n",
    "        df3 = df3.round({'time':2})\n",
    "        \n",
    "        # Get Counter 3\n",
    "        df4 = df1.iloc[num_counters-2::4, :]\n",
    "        counter_name = df4.iloc[num_counters-0][2]\n",
    "        df4 = df4.rename(columns={'value': counter_name})\n",
    "        df4.drop(df4.columns[2], axis=1, inplace = True)\n",
    "        df4 = df4.round({'time':2})\n",
    "        \n",
    "        # Get Counter 4\n",
    "        df5 = df1.iloc[num_counters-1::4, :]\n",
    "        counter_name = df5.iloc[num_counters-0][2]\n",
    "        df5 = df5.rename(columns={'value': counter_name})\n",
    "        df5.drop(df5.columns[2], axis=1, inplace = True)\n",
    "        df5 = df5.round({'time':2})\n",
    "\n",
    "        # Merge DFs\n",
    "        df6 = pd.merge(df2, df3, on = 'time', how='inner')\n",
    "        df6 = df6.round({'time':2})\n",
    "        df7 = pd.merge(df4, df5, on='time', how='inner')\n",
    "        df7 = df7.round({'time':2})\n",
    "        df8 = pd.merge(df6, df7, on='time', how='inner')\n",
    "        df8 = df8.round({'time':2})\n",
    "\n",
    "        if initial_read == 0:\n",
    "            merged_df = pd.merge(merged_df, df8, on='time', how = 'inner')\n",
    "            initial_read = 1\n",
    "        else:\n",
    "            df8 = df8.drop(columns=['cpu_core/instructions/u'])\n",
    "            merged_df = pd.merge(merged_df, df8, on='time',how='inner')\n",
    "            \n",
    "    merged_df.to_csv('traces/aligned_traces/' + job_list[10:], sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310cd36e-47a6-4013-8091-cf09a54f0d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_lists = [\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_500', \n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_502',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_505',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_520',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_523',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_525',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_531',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_541',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_548',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_557',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_503',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_507',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_508',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_510',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_511',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_519',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_521',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_527',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_538',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_544',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_549',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_ecore_3.0GHz_554'\n",
    "]\n",
    "\n",
    "num_counters = 4\n",
    "\n",
    "for job_list in job_lists:\n",
    "    input_file = open(job_list, 'r')\n",
    "    csv_files = input_file.readlines()\n",
    "\n",
    "    merged_df = pd.read_csv('blank.csv')\n",
    "    initial_read = 0\n",
    "    \n",
    "    for csv in csv_files:\n",
    "        csv = csv.strip()\n",
    "        df1 = pd.read_csv(csv)\n",
    "        df1['time'] = df1['time'].astype(float).round(2)\n",
    "        df1.drop(df1.columns[4:], axis=1, inplace=True)\n",
    "        df1.drop(df1.columns[2], axis=1, inplace=True)\n",
    "\n",
    "        # Get counter 1\n",
    "        df2 = df1.iloc[num_counters-0::4, :]\n",
    "        counter_name = df2.iloc[num_counters-0][2]\n",
    "        df2 = df2.rename(columns={'value': counter_name})\n",
    "        df2.drop(df2.columns[2], axis=1, inplace = True)\n",
    "        df2 = df2.round({'time':2})\n",
    "       \n",
    "        # Get Counter 2\n",
    "        df3 = df1.iloc[num_counters-3::4, :]\n",
    "        counter_name = df3.iloc[num_counters-0][2]\n",
    "        df3 = df3.rename(columns={'value': counter_name})\n",
    "        df3.drop(df3.columns[2], axis=1, inplace = True)\n",
    "        df3 = df3.round({'time':2})\n",
    "        \n",
    "        # Get Counter 3\n",
    "        df4 = df1.iloc[num_counters-2::4, :]\n",
    "        counter_name = df4.iloc[num_counters-0][2]\n",
    "        df4 = df4.rename(columns={'value': counter_name})\n",
    "        df4.drop(df4.columns[2], axis=1, inplace = True)\n",
    "        df4 = df4.round({'time':2})\n",
    "        \n",
    "        # Get Counter 4\n",
    "        df5 = df1.iloc[num_counters-1::4, :]\n",
    "        counter_name = df5.iloc[num_counters-0][2]\n",
    "        df5 = df5.rename(columns={'value': counter_name})\n",
    "        df5.drop(df5.columns[2], axis=1, inplace = True)\n",
    "        df5 = df5.round({'time':2})\n",
    "\n",
    "        # Merge DFs\n",
    "        df6 = pd.merge(df2, df3, on = 'time', how='inner')\n",
    "        df6 = df6.round({'time':2})\n",
    "        df7 = pd.merge(df4, df5, on='time', how='inner')\n",
    "        df7 = df7.round({'time':2})\n",
    "        df8 = pd.merge(df6, df7, on='time', how='inner')\n",
    "        df8 = df8.round({'time':2})\n",
    "\n",
    "        if initial_read == 0:\n",
    "            merged_df = pd.merge(merged_df, df8, on='time', how = 'inner')\n",
    "            initial_read = 1\n",
    "        else:\n",
    "            df8 = df8.drop(columns=['cpu_atom/instructions/u'])\n",
    "            merged_df = pd.merge(merged_df, df8, on='time',how='inner')\n",
    "            \n",
    "    merged_df.to_csv('traces/aligned_traces/' + job_list[10:], sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dff21a-6e59-4c82-ba7e-a09cb0573179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_lists = [\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_500', \n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_502',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_505',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_520',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_523',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_525',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_531',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_541',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_548',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_557',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_503',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_507',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_508',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_510',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_511',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_519',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_521',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_527',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_538',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_544',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_549',\n",
    "        'job_lists/x86_desktop_heterogeneous/x86_desktop_heterogeneous_pcore_3.0GHz_554'\n",
    "]\n",
    "\n",
    "num_counters = 4\n",
    "\n",
    "for job_list in job_lists:\n",
    "    input_file = open(job_list, 'r')\n",
    "    csv_files = input_file.readlines()\n",
    "\n",
    "    merged_df = pd.read_csv('blank.csv')\n",
    "    initial_read = 0\n",
    "    \n",
    "    for csv in csv_files:\n",
    "        csv = csv.strip()\n",
    "        df1 = pd.read_csv(csv)\n",
    "        df1['time'] = df1['time'].astype(float).round(2)\n",
    "        df1.drop(df1.columns[4:], axis=1, inplace=True)\n",
    "        df1.drop(df1.columns[2], axis=1, inplace=True)\n",
    "\n",
    "        # Get counter 1\n",
    "        df2 = df1.iloc[num_counters-0::4, :]\n",
    "        counter_name = df2.iloc[num_counters-0][2]\n",
    "        df2 = df2.rename(columns={'value': counter_name})\n",
    "        df2.drop(df2.columns[2], axis=1, inplace = True)\n",
    "        df2 = df2.round({'time':2})\n",
    "       \n",
    "        # Get Counter 2\n",
    "        df3 = df1.iloc[num_counters-3::4, :]\n",
    "        counter_name = df3.iloc[num_counters-0][2]\n",
    "        df3 = df3.rename(columns={'value': counter_name})\n",
    "        df3.drop(df3.columns[2], axis=1, inplace = True)\n",
    "        df3 = df3.round({'time':2})\n",
    "        \n",
    "        # Get Counter 3\n",
    "        df4 = df1.iloc[num_counters-2::4, :]\n",
    "        counter_name = df4.iloc[num_counters-0][2]\n",
    "        df4 = df4.rename(columns={'value': counter_name})\n",
    "        df4.drop(df4.columns[2], axis=1, inplace = True)\n",
    "        df4 = df4.round({'time':2})\n",
    "        \n",
    "        # Get Counter 4\n",
    "        df5 = df1.iloc[num_counters-1::4, :]\n",
    "        counter_name = df5.iloc[num_counters-0][2]\n",
    "        df5 = df5.rename(columns={'value': counter_name})\n",
    "        df5.drop(df5.columns[2], axis=1, inplace = True)\n",
    "        df5 = df5.round({'time':2})\n",
    "\n",
    "        # Merge DFs\n",
    "        df6 = pd.merge(df2, df3, on = 'time', how='inner')\n",
    "        df6 = df6.round({'time':2})\n",
    "        df7 = pd.merge(df4, df5, on='time', how='inner')\n",
    "        df7 = df7.round({'time':2})\n",
    "        df8 = pd.merge(df6, df7, on='time', how='inner')\n",
    "        df8 = df8.round({'time':2})\n",
    "\n",
    "        if initial_read == 0:\n",
    "            merged_df = pd.merge(merged_df, df8, on='time', how = 'inner')\n",
    "            initial_read = 1\n",
    "        else:\n",
    "            df8 = df8.drop(columns=['cpu_core/instructions/u'])\n",
    "            merged_df = pd.merge(merged_df, df8, on='time',how='inner')\n",
    "            \n",
    "    merged_df.to_csv('traces/aligned_traces/' + job_list[10:], sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd90bc3-6b53-445d-a0af-bfb25b42f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_lists = [\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_500', \n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_502',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_505',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_520',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_523',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_525',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_531',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_541',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_548',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_557',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_503',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_507',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_508',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_510',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_511',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_519',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_521',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_527',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_538',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_544',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_549',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_1.5GHz_554'\n",
    "]\n",
    "\n",
    "num_counters = 4\n",
    "\n",
    "for job_list in job_lists:\n",
    "    input_file = open(job_list, 'r')\n",
    "    csv_files = input_file.readlines()\n",
    "\n",
    "    merged_df = pd.read_csv('blank.csv')\n",
    "    initial_read = 0\n",
    "    \n",
    "    for csv in csv_files:\n",
    "        csv = csv.strip()\n",
    "        df1 = pd.read_csv(csv)\n",
    "        df1['time'] = df1['time'].astype(float).round(2)\n",
    "        df1.drop(df1.columns[4:], axis=1, inplace=True)\n",
    "        df1.drop(df1.columns[2], axis=1, inplace=True)\n",
    "\n",
    "        # Get counter 1\n",
    "        df2 = df1.iloc[num_counters-0::4, :]\n",
    "        counter_name = df2.iloc[num_counters-0][2]\n",
    "        df2 = df2.rename(columns={'value': counter_name})\n",
    "        df2.drop(df2.columns[2], axis=1, inplace = True)\n",
    "        df2 = df2.round({'time':2})\n",
    "       \n",
    "        # Get Counter 2\n",
    "        df3 = df1.iloc[num_counters-3::4, :]\n",
    "        counter_name = df3.iloc[num_counters-0][2]\n",
    "        df3 = df3.rename(columns={'value': counter_name})\n",
    "        df3.drop(df3.columns[2], axis=1, inplace = True)\n",
    "        df3 = df3.round({'time':2})\n",
    "        \n",
    "        # Get Counter 3\n",
    "        df4 = df1.iloc[num_counters-2::4, :]\n",
    "        counter_name = df4.iloc[num_counters-0][2]\n",
    "        df4 = df4.rename(columns={'value': counter_name})\n",
    "        df4.drop(df4.columns[2], axis=1, inplace = True)\n",
    "        df4 = df4.round({'time':2})\n",
    "        \n",
    "        # Get Counter 4\n",
    "        df5 = df1.iloc[num_counters-1::4, :]\n",
    "        counter_name = df5.iloc[num_counters-0][2]\n",
    "        df5 = df5.rename(columns={'value': counter_name})\n",
    "        df5.drop(df5.columns[2], axis=1, inplace = True)\n",
    "        df5 = df5.round({'time':2})\n",
    "\n",
    "        # Merge DFs\n",
    "        df6 = pd.merge(df2, df3, on = 'time', how='inner')\n",
    "        df6 = df6.round({'time':2})\n",
    "        df7 = pd.merge(df4, df5, on='time', how='inner')\n",
    "        df7 = df7.round({'time':2})\n",
    "        df8 = pd.merge(df6, df7, on='time', how='inner')\n",
    "        df8 = df8.round({'time':2})\n",
    "\n",
    "        if initial_read == 0:\n",
    "            merged_df = pd.merge(merged_df, df8, on='time', how = 'inner')\n",
    "            initial_read = 1\n",
    "        else:\n",
    "            df8 = df8.drop(columns=['instructions:u'])\n",
    "            merged_df = pd.merge(merged_df, df8, on='time',how='inner')\n",
    "            \n",
    "    merged_df.to_csv('traces/aligned_traces/' + job_list[10:], sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13f1066-07f9-4538-80e2-257df69a9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_lists = [\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_500', \n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_502',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_505',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_520',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_523',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_525',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_531',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_541',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_548',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_557',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_503',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_507',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_508',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_510',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_511',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_519',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_521',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_527',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_538',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_544',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_549',\n",
    "        'job_lists/x86_desktop_homogeneous/x86_desktop_homogeneous_3.0GHz_554'\n",
    "]\n",
    "\n",
    "num_counters = 4\n",
    "\n",
    "for job_list in job_lists:\n",
    "    input_file = open(job_list, 'r')\n",
    "    csv_files = input_file.readlines()\n",
    "\n",
    "    merged_df = pd.read_csv('blank.csv')\n",
    "    initial_read = 0\n",
    "    \n",
    "    for csv in csv_files:\n",
    "        csv = csv.strip()\n",
    "        df1 = pd.read_csv(csv)\n",
    "        df1['time'] = df1['time'].astype(float).round(2)\n",
    "        df1.drop(df1.columns[4:], axis=1, inplace=True)\n",
    "        df1.drop(df1.columns[2], axis=1, inplace=True)\n",
    "\n",
    "        # Get counter 1\n",
    "        df2 = df1.iloc[num_counters-0::4, :]\n",
    "        counter_name = df2.iloc[num_counters-0][2]\n",
    "        df2 = df2.rename(columns={'value': counter_name})\n",
    "        df2.drop(df2.columns[2], axis=1, inplace = True)\n",
    "        df2 = df2.round({'time':2})\n",
    "       \n",
    "        # Get Counter 2\n",
    "        df3 = df1.iloc[num_counters-3::4, :]\n",
    "        counter_name = df3.iloc[num_counters-0][2]\n",
    "        df3 = df3.rename(columns={'value': counter_name})\n",
    "        df3.drop(df3.columns[2], axis=1, inplace = True)\n",
    "        df3 = df3.round({'time':2})\n",
    "        \n",
    "        # Get Counter 3\n",
    "        df4 = df1.iloc[num_counters-2::4, :]\n",
    "        counter_name = df4.iloc[num_counters-0][2]\n",
    "        df4 = df4.rename(columns={'value': counter_name})\n",
    "        df4.drop(df4.columns[2], axis=1, inplace = True)\n",
    "        df4 = df4.round({'time':2})\n",
    "        \n",
    "        # Get Counter 4\n",
    "        df5 = df1.iloc[num_counters-1::4, :]\n",
    "        counter_name = df5.iloc[num_counters-0][2]\n",
    "        df5 = df5.rename(columns={'value': counter_name})\n",
    "        df5.drop(df5.columns[2], axis=1, inplace = True)\n",
    "        df5 = df5.round({'time':2})\n",
    "\n",
    "        # Merge DFs\n",
    "        df6 = pd.merge(df2, df3, on = 'time', how='inner')\n",
    "        df6 = df6.round({'time':2})\n",
    "        df7 = pd.merge(df4, df5, on='time', how='inner')\n",
    "        df7 = df7.round({'time':2})\n",
    "        df8 = pd.merge(df6, df7, on='time', how='inner')\n",
    "        df8 = df8.round({'time':2})\n",
    "\n",
    "        if initial_read == 0:\n",
    "            merged_df = pd.merge(merged_df, df8, on='time', how = 'inner')\n",
    "            initial_read = 1\n",
    "        else:\n",
    "            df8 = df8.drop(columns=['instructions:u'])\n",
    "            merged_df = pd.merge(merged_df, df8, on='time',how='inner')\n",
    "            \n",
    "    merged_df.to_csv('traces/aligned_traces/' + job_list[10:], sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae9d9a-d8b7-4a7f-9c15-b8cbb7627187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_lists = [\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_500', \n",
    "#        'job_lists/x86_server/x86_server_1.5GHz_502',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_505',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_520',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_523',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_525',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_531',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_541',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_548',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_557',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_503',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_507',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_508',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_510',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_511',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_519',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_521',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_527',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_538',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_544',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_549',\n",
    "        'job_lists/x86_server/x86_server_1.5GHz_554'\n",
    "]\n",
    "\n",
    "num_counters = 4\n",
    "\n",
    "for job_list in job_lists:\n",
    "    input_file = open(job_list, 'r')\n",
    "    csv_files = input_file.readlines()\n",
    "\n",
    "    merged_df = pd.read_csv('blank.csv')\n",
    "    initial_read = 0\n",
    "    \n",
    "    for csv in csv_files:\n",
    "        csv = csv.strip()\n",
    "        df1 = pd.read_csv(csv)\n",
    "        df1['time'] = df1['time'].astype(float).round(2)\n",
    "        df1.drop(df1.columns[4:], axis=1, inplace=True)\n",
    "        df1.drop(df1.columns[2], axis=1, inplace=True)\n",
    "\n",
    "        # Get counter 1\n",
    "        df2 = df1.iloc[num_counters-0::4, :]\n",
    "        counter_name = df2.iloc[num_counters-0][2]\n",
    "        df2 = df2.rename(columns={'value': counter_name})\n",
    "        df2.drop(df2.columns[2], axis=1, inplace = True)\n",
    "        df2 = df2.round({'time':2})\n",
    "       \n",
    "        # Get Counter 2\n",
    "        df3 = df1.iloc[num_counters-3::4, :]\n",
    "        counter_name = df3.iloc[num_counters-0][2]\n",
    "        df3 = df3.rename(columns={'value': counter_name})\n",
    "        df3.drop(df3.columns[2], axis=1, inplace = True)\n",
    "        df3 = df3.round({'time':2})\n",
    "        \n",
    "        # Get Counter 3\n",
    "        df4 = df1.iloc[num_counters-2::4, :]\n",
    "        counter_name = df4.iloc[num_counters-0][2]\n",
    "        df4 = df4.rename(columns={'value': counter_name})\n",
    "        df4.drop(df4.columns[2], axis=1, inplace = True)\n",
    "        df4 = df4.round({'time':2})\n",
    "        \n",
    "        # Get Counter 4\n",
    "        df5 = df1.iloc[num_counters-1::4, :]\n",
    "        counter_name = df5.iloc[num_counters-0][2]\n",
    "        df5 = df5.rename(columns={'value': counter_name})\n",
    "        df5.drop(df5.columns[2], axis=1, inplace = True)\n",
    "        df5 = df5.round({'time':2})\n",
    "\n",
    "        # Merge DFs\n",
    "        df6 = pd.merge(df2, df3, on = 'time', how='inner')\n",
    "        df6 = df6.round({'time':2})\n",
    "        df7 = pd.merge(df4, df5, on='time', how='inner')\n",
    "        df7 = df7.round({'time':2})\n",
    "        df8 = pd.merge(df6, df7, on='time', how='inner')\n",
    "        df8 = df8.round({'time':2})\n",
    "\n",
    "        if initial_read == 0:\n",
    "            merged_df = pd.merge(merged_df, df8, on='time', how = 'inner')\n",
    "            initial_read = 1\n",
    "        else:\n",
    "            df8 = df8.drop(columns=['instructions:u'])\n",
    "            merged_df = pd.merge(merged_df, df8, on='time',how='inner')\n",
    "            \n",
    "    merged_df.to_csv('traces/aligned_traces/' + job_list[10:], sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364e1525-1a5d-4d52-b84b-e9b01a53fd8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
