{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd87ff86-58fb-44c7-9251-f8b3f3723418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_lists = [\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_500', \n",
    "        'job_lists/arm_server/arm_server_1.5GHz_502',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_505',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_520',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_523',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_525',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_531',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_541',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_548',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_557',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_503',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_507',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_508',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_510',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_511',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_519',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_521',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_527',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_538',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_544',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_549',\n",
    "        'job_lists/arm_server/arm_server_1.5GHz_554'\n",
    "]\n",
    "\n",
    "num_counters = 4\n",
    "\n",
    "for job_list in job_lists:\n",
    "    input_file = open(job_list, 'r')\n",
    "    csv_files = input_file.readlines()\n",
    "\n",
    "    merged_df = pd.read_csv('blank.csv')\n",
    "    initial_read = 0\n",
    "    \n",
    "    for csv in csv_files:\n",
    "        csv = csv.strip()\n",
    "        df1 = pd.read_csv(csv)\n",
    "        df1['time'] = df1['time'].astype(float).round(2)\n",
    "        df1.drop(df1.columns[4:], axis=1, inplace=True)\n",
    "        df1.drop(df1.columns[2], axis=1, inplace=True)\n",
    "\n",
    "        # Get counter 1\n",
    "        df2 = df1.iloc[num_counters-0::4, :]\n",
    "        counter_name = df2.iloc[num_counters-0][2]\n",
    "        df2 = df2.rename(columns={'value': counter_name})\n",
    "        df2.drop(df2.columns[2], axis=1, inplace = True)\n",
    "        df2 = df2.round({'time':2})\n",
    "       \n",
    "        # Get Counter 2\n",
    "        df3 = df1.iloc[num_counters-3::4, :]\n",
    "        counter_name = df3.iloc[num_counters-0][2]\n",
    "        df3 = df3.rename(columns={'value': counter_name})\n",
    "        df3.drop(df3.columns[2], axis=1, inplace = True)\n",
    "        df3 = df3.round({'time':2})\n",
    "        \n",
    "        # Get Counter 3\n",
    "        df4 = df1.iloc[num_counters-2::4, :]\n",
    "        counter_name = df4.iloc[num_counters-0][2]\n",
    "        df4 = df4.rename(columns={'value': counter_name})\n",
    "        df4.drop(df4.columns[2], axis=1, inplace = True)\n",
    "        df4 = df4.round({'time':2})\n",
    "        \n",
    "        # Get Counter 4\n",
    "        df5 = df1.iloc[num_counters-1::4, :]\n",
    "        counter_name = df5.iloc[num_counters-0][2]\n",
    "        df5 = df5.rename(columns={'value': counter_name})\n",
    "        df5.drop(df5.columns[2], axis=1, inplace = True)\n",
    "        df5 = df5.round({'time':2})\n",
    "\n",
    "        # Merge DFs\n",
    "        df6 = pd.merge(df2, df3, on = 'time', how='inner')\n",
    "        df6 = df6.round({'time':2})\n",
    "        df7 = pd.merge(df4, df5, on='time', how='inner')\n",
    "        df7 = df7.round({'time':2})\n",
    "        df8 = pd.merge(df6, df7, on='time', how='inner')\n",
    "        df8 = df8.round({'time':2})\n",
    "\n",
    "        if initial_read == 0:\n",
    "            merged_df = pd.merge(merged_df, df8, on='time', how = 'inner')\n",
    "            initial_read = 1\n",
    "        else:\n",
    "            df8 = df8.drop(columns=['instructions'])\n",
    "            merged_df = pd.merge(merged_df, df8, on='time',how='inner')\n",
    "            \n",
    "    merged_df.to_csv('traces/aligned_traces/' + job_list[10:], sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb410c8-86b5-4f9c-b7c1-e482b06d202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_lists = [\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_500', \n",
    "        'job_lists/arm_server/arm_server_3.0GHz_502',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_505',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_520',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_523',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_525',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_531',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_541',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_548',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_557',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_503',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_507',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_508',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_510',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_511',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_519',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_521',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_527',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_538',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_544',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_549',\n",
    "        'job_lists/arm_server/arm_server_3.0GHz_554'\n",
    "]\n",
    "\n",
    "num_counters = 4\n",
    "\n",
    "for job_list in job_lists:\n",
    "    input_file = open(job_list, 'r')\n",
    "    csv_files = input_file.readlines()\n",
    "\n",
    "    merged_df = pd.read_csv('blank.csv')\n",
    "    initial_read = 0\n",
    "    \n",
    "    for csv in csv_files:\n",
    "        csv = csv.strip()\n",
    "        df1 = pd.read_csv(csv)\n",
    "        df1['time'] = df1['time'].astype(float).round(2)\n",
    "        df1.drop(df1.columns[4:], axis=1, inplace=True)\n",
    "        df1.drop(df1.columns[2], axis=1, inplace=True)\n",
    "\n",
    "        # Get counter 1\n",
    "        df2 = df1.iloc[num_counters-0::4, :]\n",
    "        counter_name = df2.iloc[num_counters-0][2]\n",
    "        df2 = df2.rename(columns={'value': counter_name})\n",
    "        df2.drop(df2.columns[2], axis=1, inplace = True)\n",
    "        df2 = df2.round({'time':2})\n",
    "       \n",
    "        # Get Counter 2\n",
    "        df3 = df1.iloc[num_counters-3::4, :]\n",
    "        counter_name = df3.iloc[num_counters-0][2]\n",
    "        df3 = df3.rename(columns={'value': counter_name})\n",
    "        df3.drop(df3.columns[2], axis=1, inplace = True)\n",
    "        df3 = df3.round({'time':2})\n",
    "        \n",
    "        # Get Counter 3\n",
    "        df4 = df1.iloc[num_counters-2::4, :]\n",
    "        counter_name = df4.iloc[num_counters-0][2]\n",
    "        df4 = df4.rename(columns={'value': counter_name})\n",
    "        df4.drop(df4.columns[2], axis=1, inplace = True)\n",
    "        df4 = df4.round({'time':2})\n",
    "        \n",
    "        # Get Counter 4\n",
    "        df5 = df1.iloc[num_counters-1::4, :]\n",
    "        counter_name = df5.iloc[num_counters-0][2]\n",
    "        df5 = df5.rename(columns={'value': counter_name})\n",
    "        df5.drop(df5.columns[2], axis=1, inplace = True)\n",
    "        df5 = df5.round({'time':2})\n",
    "\n",
    "        # Merge DFs\n",
    "        df6 = pd.merge(df2, df3, on = 'time', how='inner')\n",
    "        df6 = df6.round({'time':2})\n",
    "        df7 = pd.merge(df4, df5, on='time', how='inner')\n",
    "        df7 = df7.round({'time':2})\n",
    "        df8 = pd.merge(df6, df7, on='time', how='inner')\n",
    "        df8 = df8.round({'time':2})\n",
    "\n",
    "        if initial_read == 0:\n",
    "            merged_df = pd.merge(merged_df, df8, on='time', how = 'inner')\n",
    "            initial_read = 1\n",
    "        else:\n",
    "            df8 = df8.drop(columns=['instructions'])\n",
    "            merged_df = pd.merge(merged_df, df8, on='time',how='inner')\n",
    "            \n",
    "    merged_df.to_csv('traces/aligned_traces/' + job_list[10:], sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09edba8c-69f0-4307-a34a-129e0f4be269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_lists = [\n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_500',\n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_502', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_505', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_520', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_523', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_525', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_531', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_541', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_548', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_557', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_503', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_507', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_508', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_510', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_511', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_519', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_521', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_527', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_538', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_544', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_549', \n",
    "        'job_lists/arm_desktop/arm_desktop_1.5GHz_554' \n",
    "]\n",
    "\n",
    "num_counters = 4\n",
    "\n",
    "for job_list in job_lists:\n",
    "    input_file = open(job_list, 'r')\n",
    "    csv_files = input_file.readlines()\n",
    "\n",
    "    merged_df = pd.read_csv('blank.csv')\n",
    "    initial_read = 0\n",
    "    \n",
    "    for csv in csv_files:\n",
    "        csv = csv.strip()\n",
    "        df1 = pd.read_csv(csv)\n",
    "        df1['time'] = df1['time'].astype(float).round(2)\n",
    "        df1.drop(df1.columns[4:], axis=1, inplace=True)\n",
    "        df1.drop(df1.columns[2], axis=1, inplace=True)\n",
    "\n",
    "        # Get counter 1\n",
    "        df2 = df1.iloc[num_counters-0::4, :]\n",
    "        counter_name = df2.iloc[num_counters-0][2]\n",
    "        df2 = df2.rename(columns={'value': counter_name})\n",
    "        df2.drop(df2.columns[2], axis=1, inplace = True)\n",
    "        df2 = df2.round({'time':2})\n",
    "       \n",
    "        # Get Counter 2\n",
    "        df3 = df1.iloc[num_counters-3::4, :]\n",
    "        counter_name = df3.iloc[num_counters-0][2]\n",
    "        df3 = df3.rename(columns={'value': counter_name})\n",
    "        df3.drop(df3.columns[2], axis=1, inplace = True)\n",
    "        df3 = df3.round({'time':2})\n",
    "        \n",
    "        # Get Counter 3\n",
    "        df4 = df1.iloc[num_counters-2::4, :]\n",
    "        counter_name = df4.iloc[num_counters-0][2]\n",
    "        df4 = df4.rename(columns={'value': counter_name})\n",
    "        df4.drop(df4.columns[2], axis=1, inplace = True)\n",
    "        df4 = df4.round({'time':2})\n",
    "        \n",
    "        # Get Counter 4\n",
    "        df5 = df1.iloc[num_counters-1::4, :]\n",
    "        counter_name = df5.iloc[num_counters-0][2]\n",
    "        df5 = df5.rename(columns={'value': counter_name})\n",
    "        df5.drop(df5.columns[2], axis=1, inplace = True)\n",
    "        df5 = df5.round({'time':2})\n",
    "\n",
    "        # Merge DFs\n",
    "        df6 = pd.merge(df2, df3, on = 'time', how='inner')\n",
    "        df6 = df6.round({'time':2})\n",
    "        df7 = pd.merge(df4, df5, on='time', how='inner')\n",
    "        df7 = df7.round({'time':2})\n",
    "        df8 = pd.merge(df6, df7, on='time', how='inner')\n",
    "        df8 = df8.round({'time':2})\n",
    "\n",
    "        if initial_read == 0:\n",
    "            merged_df = pd.merge(merged_df, df8, on='time', how = 'inner')\n",
    "            initial_read = 1\n",
    "        else:\n",
    "            df8 = df8.drop(columns=['instructions'])\n",
    "            merged_df = pd.merge(merged_df, df8, on='time',how='left')\n",
    "            \n",
    "    merged_df.to_csv('traces/aligned_traces/' + job_list[10:], sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f351ed6-5e41-4e5a-952b-7be2ded0a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_lists = [\n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_500',\n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_502', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_505', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_520', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_523', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_525', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_531', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_541', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_548', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_557', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_503', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_507', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_508', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_510', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_511', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_519', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_521', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_527', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_538', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_544', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_549', \n",
    "        'job_lists/arm_desktop/arm_desktop_3.0GHz_554' \n",
    "]\n",
    "\n",
    "num_counters = 4\n",
    "\n",
    "for job_list in job_lists:\n",
    "    input_file = open(job_list, 'r')\n",
    "    csv_files = input_file.readlines()\n",
    "\n",
    "    merged_df = pd.read_csv('blank.csv')\n",
    "    initial_read = 0\n",
    "    \n",
    "    for csv in csv_files:\n",
    "        csv = csv.strip()\n",
    "        df1 = pd.read_csv(csv)\n",
    "        df1['time'] = df1['time'].astype(float).round(2)\n",
    "        df1.drop(df1.columns[4:], axis=1, inplace=True)\n",
    "        df1.drop(df1.columns[2], axis=1, inplace=True)\n",
    "\n",
    "        # Get counter 1\n",
    "        df2 = df1.iloc[num_counters-0::4, :]\n",
    "        counter_name = df2.iloc[num_counters-0][2]\n",
    "        df2 = df2.rename(columns={'value': counter_name})\n",
    "        df2.drop(df2.columns[2], axis=1, inplace = True)\n",
    "        df2 = df2.round({'time':2})\n",
    "       \n",
    "        # Get Counter 2\n",
    "        df3 = df1.iloc[num_counters-3::4, :]\n",
    "        counter_name = df3.iloc[num_counters-0][2]\n",
    "        df3 = df3.rename(columns={'value': counter_name})\n",
    "        df3.drop(df3.columns[2], axis=1, inplace = True)\n",
    "        df3 = df3.round({'time':2})\n",
    "        \n",
    "        # Get Counter 3\n",
    "        df4 = df1.iloc[num_counters-2::4, :]\n",
    "        counter_name = df4.iloc[num_counters-0][2]\n",
    "        df4 = df4.rename(columns={'value': counter_name})\n",
    "        df4.drop(df4.columns[2], axis=1, inplace = True)\n",
    "        df4 = df4.round({'time':2})\n",
    "        \n",
    "        # Get Counter 4\n",
    "        df5 = df1.iloc[num_counters-1::4, :]\n",
    "        counter_name = df5.iloc[num_counters-0][2]\n",
    "        df5 = df5.rename(columns={'value': counter_name})\n",
    "        df5.drop(df5.columns[2], axis=1, inplace = True)\n",
    "        df5 = df5.round({'time':2})\n",
    "\n",
    "        # Merge DFs\n",
    "        df6 = pd.merge(df2, df3, on = 'time', how='inner')\n",
    "        df6 = df6.round({'time':2})\n",
    "        df7 = pd.merge(df4, df5, on='time', how='inner')\n",
    "        df7 = df7.round({'time':2})\n",
    "        df8 = pd.merge(df6, df7, on='time', how='inner')\n",
    "        df8 = df8.round({'time':2})\n",
    "\n",
    "        if initial_read == 0:\n",
    "            merged_df = pd.merge(merged_df, df8, on='time', how = 'inner')\n",
    "            initial_read = 1\n",
    "        else:\n",
    "            df8 = df8.drop(columns=['instructions'])\n",
    "            merged_df = pd.merge(merged_df, df8, on='time',how='left')\n",
    "            \n",
    "    merged_df.to_csv('traces/aligned_traces/' + job_list[10:], sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae58ef-e53b-4cc1-b745-81d1626c8998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_lists = [\n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_500',\n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_502', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_505', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_520', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_523', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_525', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_531', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_541', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_548', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_557', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_503', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_507', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_508', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_510', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_511', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_519', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_521', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_527', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_538', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_544', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_549', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_InO_554' \n",
    "]\n",
    "\n",
    "num_counters = 2\n",
    "\n",
    "for job_list in job_lists:\n",
    "    input_file = open(job_list, 'r')\n",
    "    csv_files = input_file.readlines()\n",
    "\n",
    "    merged_df = pd.read_csv('blank.csv')\n",
    "    initial_read = 0\n",
    "    \n",
    "    for csv in csv_files:\n",
    "        csv = csv.strip()\n",
    "        df1 = pd.read_csv(csv)\n",
    "        df1['time'] = df1['time'].astype(float).round(2)\n",
    "        df1.drop(df1.columns[4:], axis=1, inplace=True)\n",
    "        df1.drop(df1.columns[2], axis=1, inplace=True)\n",
    "\n",
    "        # Get counter 1\n",
    "        df2 = df1.iloc[num_counters-0::2, :]\n",
    "        counter_name = df2.iloc[num_counters-0][2]\n",
    "        df2 = df2.rename(columns={'value': counter_name})\n",
    "        df2.drop(df2.columns[2], axis=1, inplace = True)\n",
    "        df2 = df2.round({'time':2})\n",
    "        \n",
    "        # Get Counter 2\n",
    "        df3 = df1.iloc[num_counters-1::2, :]\n",
    "        counter_name = df3.iloc[num_counters-1][2]\n",
    "        df3 = df3.rename(columns={'value': counter_name})\n",
    "        df3.drop(df3.columns[2], axis=1, inplace = True)\n",
    "        df3 = df3.round({'time':2})\n",
    "        \n",
    "        # Merge DFs\n",
    "        df4 = pd.merge(df2, df3, on = 'time', how='inner')\n",
    "        df4 = df4.round({'time':2})\n",
    "        \n",
    "        if initial_read == 0:\n",
    "            merged_df = pd.merge(merged_df, df4, on='time', how = 'inner')\n",
    "            initial_read = 1\n",
    "        else:\n",
    "            df4 = df4.drop(columns=['instructions:u'])\n",
    "            merged_df = pd.merge(merged_df, df4, on='time',how='left')\n",
    "            \n",
    "    merged_df.to_csv('traces/aligned_traces/' + job_list[10:], sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d97f342-2ddf-418c-932c-29fc3d7e481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_lists = [\n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_500',\n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_502', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_505', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_520', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_523', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_525', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_531', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_541', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_548', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_557', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_503', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_507', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_508', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_510', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_511', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_519', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_521', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_527', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_538', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_544', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_549', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_554' \n",
    "]\n",
    "\n",
    "num_counters = 2\n",
    "\n",
    "for job_list in job_lists:\n",
    "    input_file = open(job_list, 'r')\n",
    "    csv_files = input_file.readlines()\n",
    "\n",
    "    merged_df = pd.read_csv('blank.csv')\n",
    "    initial_read = 0\n",
    "    \n",
    "    for csv in csv_files:\n",
    "        csv = csv.strip()\n",
    "        df1 = pd.read_csv(csv)\n",
    "        df1['time'] = df1['time'].astype(float).round(2)\n",
    "        df1.drop(df1.columns[4:], axis=1, inplace=True)\n",
    "        df1.drop(df1.columns[2], axis=1, inplace=True)\n",
    "\n",
    "        # Get counter 1\n",
    "        df2 = df1.iloc[num_counters-0::2, :]\n",
    "        counter_name = df2.iloc[num_counters-0][2]\n",
    "        df2 = df2.rename(columns={'value': counter_name})\n",
    "        df2.drop(df2.columns[2], axis=1, inplace = True)\n",
    "        df2 = df2.round({'time':2})\n",
    "        \n",
    "        # Get Counter 2\n",
    "        df3 = df1.iloc[num_counters-1::2, :]\n",
    "        counter_name = df3.iloc[num_counters-1][2]\n",
    "        df3 = df3.rename(columns={'value': counter_name})\n",
    "        df3.drop(df3.columns[2], axis=1, inplace = True)\n",
    "        df3 = df3.round({'time':2})\n",
    "        \n",
    "        # Merge DFs\n",
    "        df4 = pd.merge(df2, df3, on = 'time', how='inner')\n",
    "        df4 = df4.round({'time':2})\n",
    "        \n",
    "        if initial_read == 0:\n",
    "            merged_df = pd.merge(merged_df, df4, on='time', how = 'inner')\n",
    "            initial_read = 1\n",
    "        else:\n",
    "            df4 = df4.drop(columns=['instructions:u'])\n",
    "            merged_df = pd.merge(merged_df, df4, on='time',how='left')\n",
    "            \n",
    "    merged_df.to_csv('traces/aligned_traces/' + job_list[10:], sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fab58a-674f-4e22-b265-0956589d6d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_lists = [\n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_500',\n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_502', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_505', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_520', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_523', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_525', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_531', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_541', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_548', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_557', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_503', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_507', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_508', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_510', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_511', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_519', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_521', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_527', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_538', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_544', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_549', \n",
    "        'job_lists/arm_edge_heterogeneous/arm_edge_heterogeneous_OOO_cache_554' \n",
    "]\n",
    "\n",
    "num_counters = 2\n",
    "\n",
    "for job_list in job_lists:\n",
    "    input_file = open(job_list, 'r')\n",
    "    csv_files = input_file.readlines()\n",
    "\n",
    "    merged_df = pd.read_csv('blank.csv')\n",
    "    initial_read = 0\n",
    "    \n",
    "    for csv in csv_files:\n",
    "        csv = csv.strip()\n",
    "        df1 = pd.read_csv(csv)\n",
    "        df1['time'] = df1['time'].astype(float).round(2)\n",
    "        df1.drop(df1.columns[4:], axis=1, inplace=True)\n",
    "        df1.drop(df1.columns[2], axis=1, inplace=True)\n",
    "\n",
    "        # Get counter 1\n",
    "        df2 = df1.iloc[num_counters-0::2, :]\n",
    "        counter_name = df2.iloc[num_counters-0][2]\n",
    "        df2 = df2.rename(columns={'value': counter_name})\n",
    "        df2.drop(df2.columns[2], axis=1, inplace = True)\n",
    "        df2 = df2.round({'time':2})\n",
    "        \n",
    "        # Get Counter 2\n",
    "        df3 = df1.iloc[num_counters-1::2, :]\n",
    "        counter_name = df3.iloc[num_counters-1][2]\n",
    "        df3 = df3.rename(columns={'value': counter_name})\n",
    "        df3.drop(df3.columns[2], axis=1, inplace = True)\n",
    "        df3 = df3.round({'time':2})\n",
    "        \n",
    "        # Merge DFs\n",
    "        df4 = pd.merge(df2, df3, on = 'time', how='inner')\n",
    "        df4 = df4.round({'time':2})\n",
    "        \n",
    "        if initial_read == 0:\n",
    "            merged_df = pd.merge(merged_df, df4, on='time', how = 'inner')\n",
    "            initial_read = 1\n",
    "        else:\n",
    "            df4 = df4.drop(columns=['instructions:u'])\n",
    "            merged_df = pd.merge(merged_df, df4, on='time',how='left')\n",
    "            \n",
    "    merged_df.to_csv('traces/aligned_traces/' + job_list[10:], sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8ff3fc-22b5-497d-8bf1-cba26e6c4edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(2,5,figsize=(20,8))\n",
    "ax[0][0].plot()\n",
    "ax[0][0].set_title('500')\n",
    "ax[0][1].plot()\n",
    "ax[0][1].set_title('502')\n",
    "ax[0][2].plot()\n",
    "ax[0][2].set_title('505')\n",
    "ax[0][3].plot()\n",
    "ax[0][3].set_title('520')\n",
    "ax[0][4].plot()\n",
    "ax[0][4].set_title('523')\n",
    "ax[1][0].plot()\n",
    "ax[1][0].set_title('525')\n",
    "ax[1][1].plot()\n",
    "ax[1][1].set_title('531')\n",
    "ax[1][2].plot()\n",
    "ax[1][2].set_title('541')\n",
    "ax[1][3].plot()\n",
    "ax[1][3].set_title('548')\n",
    "ax[1][4].plot()\n",
    "ax[1][4].set_title('557')\n",
    "\n",
    "csv_list = ['500.csv','502.csv','505.csv','520.csv','523.csv','525.csv','531.csv','541.csv','548.csv','557.csv']\n",
    "\n",
    "for csv in range(0,len(csv_list)):\n",
    "    df1 = pd.read_csv('inst_aligned/' + csv_list[csv])\n",
    "    df1 = df1.apply(pd.to_numeric,errors='coerce').fillna(0)\n",
    "    \n",
    "    # Extract features\n",
    "    features = ['instruction','cpu-cycle','armv8_pmuv3/stall_backen','armv8_pmuv3/stall_fronten','armv8_pmuv3/br_mis_pre','armv8_pmuv3/br_pre','armv8_pmuv3/br_retire','armv8_pmuv3/inst_spe','armv8_pmuv3/inst_retire','armv8_pmuv3/l1d_cach','armv8_pmuv3/l1d_cache_refil','armv8_pmuv3/l1d_cache_w','armv8_pmuv3/l1d_tl','armv8_pmuv3/l1d_tlb_refil','armv8_pmuv3/l1i_cach','armv8_pmuv3/l1i_cache_refil','armv8_pmuv3/l1i_tl','armv8_pmuv3/l1i_tlb_refil','armv8_pmuv3/l2d_cach','armv8_pmuv3/l2d_cache_allocat','armv8_pmuv3/l2d_cache_refil','armv8_pmuv3/l2d_cache_w','armv8_pmuv3/l2d_tl','armv8_pmuv3/l2d_tlb_refil','armv8_pmuv3/l3d_cach','armv8_pmuv3/l3d_cache_allocat','armv8_pmuv3/l3d_cache_refil','armv8_pmuv3/l3d_cache_w','armv8_pmuv3/mem_acces']\n",
    "    X = df1[features]\n",
    "    Y = df1['core']\n",
    "\n",
    "    pca1 = PCA(n_components=2)\n",
    "    pca1_features = pca1.fit_transform(X)\n",
    "  \n",
    "    pca1_df = pd.DataFrame(\n",
    "        data=pca1_features,\n",
    "        columns=['PC1','PC2'])\n",
    "\n",
    "    target_names = {\n",
    "        0:'InO',\n",
    "        1:'OOO'\n",
    "    }\n",
    "\n",
    "    pca1_df['target'] = Y\n",
    "    pca1_df['target'] = pca1_df['target'].map(target_names)\n",
    "    \n",
    "    if csv == 0:\n",
    "        groups = pca1_df.groupby('target')\n",
    "        for name, group in groups:\n",
    "            ax[0][0].scatter(group.PC1, group.PC2, edgecolor='k', s=25)\n",
    "    \n",
    "    elif csv == 1:\n",
    "        groups = pca1_df.groupby('target')\n",
    "        for name, group in groups:\n",
    "            ax[0][1].scatter(group.PC1, group.PC2, edgecolor='k', s=25)\n",
    "\n",
    "    elif csv == 2:\n",
    "        groups = pca1_df.groupby('target')\n",
    "        for name, group in groups:\n",
    "            ax[0][2].scatter(group.PC1, group.PC2, edgecolor='k', s=25)\n",
    "\n",
    "    elif csv == 3:\n",
    "        groups = pca1_df.groupby('target')\n",
    "        for name, group in groups:\n",
    "            ax[0][3].scatter(group.PC1, group.PC2, edgecolor='k', s=25)\n",
    "\n",
    "    elif csv == 4:\n",
    "        groups = pca1_df.groupby('target')\n",
    "        for name, group in groups:\n",
    "            ax[0][4].scatter(group.PC1, group.PC2, edgecolor='k', s=25)\n",
    "\n",
    "    elif csv == 5:\n",
    "        groups = pca1_df.groupby('target')\n",
    "        for name, group in groups:\n",
    "            ax[1][0].scatter(group.PC1, group.PC2, edgecolor='k', s=25)\n",
    "\n",
    "    elif csv == 6:\n",
    "        groups = pca1_df.groupby('target')\n",
    "        for name, group in groups:\n",
    "            ax[1][1].scatter(group.PC1, group.PC2, edgecolor='k', s=25)\n",
    "\n",
    "    elif csv == 7:\n",
    "        groups = pca1_df.groupby('target')\n",
    "        for name, group in groups:\n",
    "            ax[1][2].scatter(group.PC1, group.PC2, edgecolor='k', s=25)\n",
    "\n",
    "    elif csv == 8:\n",
    "        groups = pca1_df.groupby('target')\n",
    "        for name, group in groups:\n",
    "            ax[1][3].scatter(group.PC1, group.PC2, edgecolor='k', s=25)\n",
    "\n",
    "    elif csv == 9:\n",
    "        groups = pca1_df.groupby('target')\n",
    "        for name, group in groups:\n",
    "            ax[1][4].scatter(group.PC1, group.PC2, edgecolor='k', s=25)\n",
    "        \n",
    "plt.show()\n",
    "plt.savefig('PCA_intrate.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
